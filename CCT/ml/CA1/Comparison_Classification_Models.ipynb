{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01397cb-e632-480e-b00b-0586ab000a4f",
   "metadata": {},
   "source": [
    "# Estimation of Obesity Levels Based On Eating Habits and Physical Condition\n",
    "* This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. The data contains 17 attributes and 2111 records, the records are labeled with the class variable NObesity (Obesity Level), that allows classification of the data using the values of Insufficient Weight, Normal Weight, Overweight Level I, Overweight Level II, Obesity Type I, Obesity Type II and Obesity Type III. 77% of the data was generated synthetically using the Weka tool and the SMOTE filter, 23% of the data was collected directly from users through a web platform.\n",
    "\r\n",
    "\n",
    "* https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da7afb1f-1ad4-48dc-99a9-4b3eae28f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a365c8-9ecb-41b6-9fb6-8980382962e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>53.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>55.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Motorbike</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>53.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>68.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
       "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
       "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
       "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
       "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
       "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
       "5    Male  29.0    1.62    53.0                             no  yes   2.0   \n",
       "6  Female  23.0    1.50    55.0                            yes  yes   3.0   \n",
       "7    Male  22.0    1.64    53.0                             no   no   2.0   \n",
       "8    Male  24.0    1.78    64.0                            yes  yes   3.0   \n",
       "9    Male  22.0    1.72    68.0                            yes  yes   2.0   \n",
       "\n",
       "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
       "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
       "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
       "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
       "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
       "4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
       "5  3.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
       "6  3.0  Sometimes    no   2.0   no  1.0  0.0   Sometimes   \n",
       "7  3.0  Sometimes    no   2.0   no  3.0  0.0   Sometimes   \n",
       "8  3.0  Sometimes    no   2.0   no  1.0  1.0  Frequently   \n",
       "9  3.0  Sometimes    no   2.0   no  1.0  1.0          no   \n",
       "\n",
       "                  MTRANS           NObeyesdad  \n",
       "0  Public_Transportation        Normal_Weight  \n",
       "1  Public_Transportation        Normal_Weight  \n",
       "2  Public_Transportation        Normal_Weight  \n",
       "3                Walking   Overweight_Level_I  \n",
       "4  Public_Transportation  Overweight_Level_II  \n",
       "5             Automobile        Normal_Weight  \n",
       "6              Motorbike        Normal_Weight  \n",
       "7  Public_Transportation        Normal_Weight  \n",
       "8  Public_Transportation        Normal_Weight  \n",
       "9  Public_Transportation        Normal_Weight  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the following libraries for teh classification task\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Load the data\n",
    "# https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition\n",
    "df = pd.read_csv('ObesityDataSet_raw_and_data_sinthetic.csv')\n",
    "\n",
    "# Display top 10 records\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca1e5b72-e444-4eb2-92ed-b3fdd0d80e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "Gender                            0\n",
      "Age                               0\n",
      "Height                            0\n",
      "Weight                            0\n",
      "family_history_with_overweight    0\n",
      "FAVC                              0\n",
      "FCVC                              0\n",
      "NCP                               0\n",
      "CAEC                              0\n",
      "SMOKE                             0\n",
      "CH2O                              0\n",
      "SCC                               0\n",
      "FAF                               0\n",
      "TUE                               0\n",
      "CALC                              0\n",
      "MTRANS                            0\n",
      "NObeyesdad                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values and we introduce two missing values in the dataset\n",
    "missing_counts = df.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc91152-d8be-4856-b458-0dce2276b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in df.select_dtypes(include=[object]).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le                   # Store encoders if needed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ac9cca-b295-4492-9c4d-7edb1ac2209f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight  family_history_with_overweight  FAVC  FCVC  \\\n",
       "0       0  21.0    1.62    64.0                               1     0   2.0   \n",
       "1       0  21.0    1.52    56.0                               1     0   3.0   \n",
       "2       1  23.0    1.80    77.0                               1     0   2.0   \n",
       "3       1  27.0    1.80    87.0                               0     0   3.0   \n",
       "4       1  22.0    1.78    89.8                               0     0   2.0   \n",
       "5       1  29.0    1.62    53.0                               0     1   2.0   \n",
       "6       0  23.0    1.50    55.0                               1     1   3.0   \n",
       "7       1  22.0    1.64    53.0                               0     0   2.0   \n",
       "8       1  24.0    1.78    64.0                               1     1   3.0   \n",
       "9       1  22.0    1.72    68.0                               1     1   2.0   \n",
       "\n",
       "   NCP  CAEC  SMOKE  CH2O  SCC  FAF  TUE  CALC  MTRANS  NObeyesdad  \n",
       "0  3.0     2      0   2.0    0  0.0  1.0     3       3           1  \n",
       "1  3.0     2      1   3.0    1  3.0  0.0     2       3           1  \n",
       "2  3.0     2      0   2.0    0  2.0  1.0     1       3           1  \n",
       "3  3.0     2      0   2.0    0  2.0  0.0     1       4           5  \n",
       "4  1.0     2      0   2.0    0  0.0  0.0     2       3           6  \n",
       "5  3.0     2      0   2.0    0  0.0  0.0     2       0           1  \n",
       "6  3.0     2      0   2.0    0  1.0  0.0     2       2           1  \n",
       "7  3.0     2      0   2.0    0  3.0  0.0     2       3           1  \n",
       "8  3.0     2      0   2.0    0  1.0  1.0     1       3           1  \n",
       "9  3.0     2      0   2.0    0  1.0  1.0     3       3           1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55efb5ec-95b0-4fb0-9c8f-161cd0a8c12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Gender        Age    Height      Weight  family_history_with_overweight  \\\n",
      "0          0  21.000000  1.620000   64.000000                               1   \n",
      "1          0  21.000000  1.520000   56.000000                               1   \n",
      "2          1  23.000000  1.800000   77.000000                               1   \n",
      "3          1  27.000000  1.800000   87.000000                               0   \n",
      "4          1  22.000000  1.780000   89.800000                               0   \n",
      "...      ...        ...       ...         ...                             ...   \n",
      "2106       0  20.976842  1.710730  131.408528                               1   \n",
      "2107       0  21.982942  1.748584  133.742943                               1   \n",
      "2108       0  22.524036  1.752206  133.689352                               1   \n",
      "2109       0  24.361936  1.739450  133.346641                               1   \n",
      "2110       0  23.664709  1.738836  133.472641                               1   \n",
      "\n",
      "      FAVC  FCVC  NCP  CAEC  SMOKE      CH2O  SCC       FAF       TUE  CALC  \\\n",
      "0        0   2.0  3.0     2      0  2.000000    0  0.000000  1.000000     3   \n",
      "1        0   3.0  3.0     2      1  3.000000    1  3.000000  0.000000     2   \n",
      "2        0   2.0  3.0     2      0  2.000000    0  2.000000  1.000000     1   \n",
      "3        0   3.0  3.0     2      0  2.000000    0  2.000000  0.000000     1   \n",
      "4        0   2.0  1.0     2      0  2.000000    0  0.000000  0.000000     2   \n",
      "...    ...   ...  ...   ...    ...       ...  ...       ...       ...   ...   \n",
      "2106     1   3.0  3.0     2      0  1.728139    0  1.676269  0.906247     2   \n",
      "2107     1   3.0  3.0     2      0  2.005130    0  1.341390  0.599270     2   \n",
      "2108     1   3.0  3.0     2      0  2.054193    0  1.414209  0.646288     2   \n",
      "2109     1   3.0  3.0     2      0  2.852339    0  1.139107  0.586035     2   \n",
      "2110     1   3.0  3.0     2      0  2.863513    0  1.026452  0.714137     2   \n",
      "\n",
      "      MTRANS  \n",
      "0          3  \n",
      "1          3  \n",
      "2          3  \n",
      "3          4  \n",
      "4          3  \n",
      "...      ...  \n",
      "2106       3  \n",
      "2107       3  \n",
      "2108       3  \n",
      "2109       3  \n",
      "2110       3  \n",
      "\n",
      "[2111 rows x 16 columns] \n",
      " 0       1\n",
      "1       1\n",
      "2       1\n",
      "3       5\n",
      "4       6\n",
      "       ..\n",
      "2106    4\n",
      "2107    4\n",
      "2108    4\n",
      "2109    4\n",
      "2110    4\n",
      "Name: NObeyesdad, Length: 2111, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Define features and target variable\n",
    "X = df.drop(columns='NObeyesdad')  # Features\n",
    "y = df['NObeyesdad']               # Target variable showed the  class variable NObesity (Obesity Level), that allows classification of the data using the values of Insufficient Weight, Normal Weight, Overweight Level I, Overweight Level II, Obesity Type I, Obesity Type II and Obesity Type III. \n",
    "\n",
    "print(X, '\\n', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a50f1376-9eb2-48d5-a445-5ccd484ac597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each class in 'NObeyesdad' (Obesity Level):\n",
      "NObeyesdad\n",
      "2    351\n",
      "4    324\n",
      "3    297\n",
      "5    290\n",
      "6    290\n",
      "1    287\n",
      "0    272\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show count of each class in the target variable\n",
    "class_counts = y.value_counts()\n",
    "print(\"Count of each class in 'NObeyesdad' (Obesity Level):\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2901bb3a-5e2e-42cf-9e12-32ed5592c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb23061e-56f9-4f03-851f-ae67d2b8f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifiers for ML models\n",
    "classifiers = {\n",
    "    \"k-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Support Vector Machine\": SVC(kernel='linear', random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca11c535-e510-463a-a330-f397b64110ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate ML model classifiers for Obesity dataset\n",
    "results = []\n",
    "for name, classifier in classifiers.items():\n",
    "    # Train the classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1_score = report['weighted avg']['f1-score']\n",
    "    \n",
    "    # Append results\n",
    "    results.append([name, accuracy, precision, recall, f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfd1419b-403c-4519-bd4b-a6b07c91a67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Metrics on Test Set:\n",
      "                    Model  Accuracy  Precision    Recall  F1 Score\n",
      "0     k-Nearest Neighbors  0.881797   0.882473  0.881797  0.872854\n",
      "1           Decision Tree  0.933806   0.934424  0.933806  0.933893\n",
      "2           Random Forest  0.955083   0.955594  0.955083  0.955281\n",
      "3     Logistic Regression  0.808511   0.808556  0.808511  0.802781\n",
      "4  Support Vector Machine  0.886525   0.890636  0.886525  0.882978\n"
     ]
    }
   ],
   "source": [
    "# Convert results to DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
    "print(\"Model Performance Metrics on Test Set:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "880f8856-6061-4da5-b1d3-ec7224dc76c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Accuracy Scores:\n",
      "                    Model  Mean CV Accuracy\n",
      "0     k-Nearest Neighbors          0.877813\n",
      "1           Decision Tree          0.925667\n",
      "2           Random Forest          0.936614\n",
      "3     Logistic Regression          0.800642\n",
      "4  Support Vector Machine          0.875001\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation for accuracy on the full dataset\n",
    "cv_results = []\n",
    "for name, classifier in classifiers.items():\n",
    "    cv_scores = cross_val_score(classifier, X, y, cv=5, scoring='accuracy')\n",
    "    cv_results.append([name, cv_scores.mean()])\n",
    "\n",
    "# Display cross-validation results\n",
    "cv_results_df = pd.DataFrame(cv_results, columns=[\"Model\", \"Mean CV Accuracy\"])\n",
    "print(\"\\nCross-Validation Accuracy Scores:\")\n",
    "print(cv_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdbe432-fa32-4742-8b50-63fb538d8118",
   "metadata": {},
   "source": [
    "# Apply SMOTE to balance the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39eec092-ff5d-42be-a9a7-de97fe4b3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['NObeyesdad']               # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7ee3c27-9d92-4a1e-bb28-21517e4c3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27216bd9-1166-4aa1-b537-7301e208c4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each class in 'NObeyesdad' (Obesity Level):\n",
      "NObeyesdad\n",
      "2    273\n",
      "4    261\n",
      "6    240\n",
      "3    239\n",
      "5    234\n",
      "1    225\n",
      "0    216\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show count of each class in the target variable\n",
    "class_counts = y_train.value_counts()\n",
    "print(\"Count of each class in 'NObeyesdad' (Obesity Level):\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "346ed2ff-de4f-4e49-aec4-b3c9d78dff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to balance the classes in the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "XS_train, ys_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44c6437c-1e41-463b-b074-1c6661950237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each class in 'NObeyesdad' (Obesity Level):\n",
      "NObeyesdad\n",
      "1    273\n",
      "4    273\n",
      "2    273\n",
      "0    273\n",
      "3    273\n",
      "6    273\n",
      "5    273\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show count of each class in the target variable\n",
    "class_counts = ys_train.value_counts()\n",
    "print(\"Count of each class in 'NObeyesdad' (Obesity Level):\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8bb118a-3ea7-483b-b36b-2619c9e575b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate classifiers\n",
    "results = []\n",
    "for name, classifier in classifiers.items():\n",
    "    # Train the classifier\n",
    "    classifier.fit(XS_train, ys_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1_score = report['weighted avg']['f1-score']\n",
    "    \n",
    "    # Append results\n",
    "    results.append([name, accuracy, precision, recall, f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bad4b43-bfff-4dbb-b1a2-6e5107c08b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Metrics on Test Set:\n",
      "                    Model  Accuracy  Precision    Recall  F1 Score\n",
      "0     k-Nearest Neighbors  0.881797   0.880139  0.881797  0.874499\n",
      "1           Decision Tree  0.926714   0.927782  0.926714  0.927012\n",
      "2           Random Forest  0.950355   0.951542  0.950355  0.950579\n",
      "3     Logistic Regression  0.813239   0.815528  0.813239  0.808008\n",
      "4  Support Vector Machine  0.888889   0.892595  0.888889  0.886023\n"
     ]
    }
   ],
   "source": [
    "# Convert results to DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
    "print(\"Model Performance Metrics on Test Set:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5d5eb06-905a-47ea-8194-5ff0c49e1d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Accuracy Scores:\n",
      "                    Model  Mean CV Accuracy\n",
      "0     k-Nearest Neighbors          0.877813\n",
      "1           Decision Tree          0.925667\n",
      "2           Random Forest          0.936614\n",
      "3     Logistic Regression          0.800642\n",
      "4  Support Vector Machine          0.875001\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation for accuracy on the full dataset\n",
    "cv_results = []\n",
    "for name, classifier in classifiers.items():\n",
    "    cv_scores = cross_val_score(classifier, X, y, cv=5, scoring='accuracy')\n",
    "    cv_results.append([name, cv_scores.mean()])\n",
    "\n",
    "# Display cross-validation results\n",
    "cv_results_df = pd.DataFrame(cv_results, columns=[\"Model\", \"Mean CV Accuracy\"])\n",
    "print(\"\\nCross-Validation Accuracy Scores:\")\n",
    "print(cv_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64243e2-d7ea-4501-8ac9-22d9bee339d1",
   "metadata": {},
   "source": [
    "# Develop a GridSearhCV for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcf7c33a-5253-47fc-80a3-0bdf47b052c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"k-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Support Vector Machine\": SVC(kernel='linear', random_state=42),\n",
    "    \"Neural Network\": MLPClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34e69919-517e-4d0c-806f-230ba6640a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grids for each classifier\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"solver\": ['lbfgs', 'liblinear'],\n",
    "        \"penalty\": ['l2']\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"max_depth\": [None, 10, 20, 30],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [None, 10, 20, 30],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    },\n",
    "    \"k-Nearest Neighbors\": {\n",
    "        \"n_neighbors\": [3, 5, 7, 9],\n",
    "        \"algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute']     #The \"algorithm\" parameter in the KNeighborsClassifier controls how the nearest neighbors search is performed. It determines the method used to compute distances between points in the feature space and find the nearest neighbors. There are four options for the \"algorithm\"\n",
    "    },\n",
    "    \"Support Vector Machine\": {\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"kernel\": ['linear', 'rbf'],\n",
    "        \"gamma\": ['scale', 'auto']\n",
    "    },\n",
    "\n",
    "    \"Neural Network\": {\n",
    "        \"hidden_layer_sizes\": [(50,), (100,), (50)],     # (50,) → A network with 1 hidden layer of 50 neurons. (100,) → A network with 1 hidden layer of 100 neurons. (50,) → A network with 1 hidden layer of 50 neurons (same as the first one).\n",
    "        \"activation\": ['sigmoid', 'relu'],\n",
    "        \"solver\": ['adam', 'sgd'],\n",
    "        \"learning_rate\": ['constant', 'adaptive']       # 'constant': The learning rate remains fixed throughout training. It doesn’t change., 'adaptive': The learning rate starts at a given value and decreases over time if the model's performance plateaus (i.e., when the model is no longer improving after a set number of iterations).\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fc44222-9fa7-45d3-939c-4cbda8055aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for Logistic Regression...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Running GridSearchCV for Decision Tree...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Running GridSearchCV for Random Forest...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Running GridSearchCV for k-Nearest Neighbors...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Running GridSearchCV for Support Vector Machine...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Running GridSearchCV for Neural Network...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "# Apply GridSearchCV for each classifier and evaluate performance metric scores\n",
    "results = []\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"Running GridSearchCV for {name}...\")\n",
    "    grid_search = GridSearchCV(estimator=classifier, param_grid=param_grids[name], cv = 5, n_jobs = -1, verbose = 2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model from grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Predict on the test set with the best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1_score = report['weighted avg']['f1-score']\n",
    "    \n",
    "    # Append results\n",
    "    results.append([name, accuracy, precision, recall, f1_score, grid_search.best_params_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e9fd5b2-fe56-4bff-9160-aa96a319c1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Metrics on Test Set after GridSearchCV:\n",
      "                    Model  Accuracy  Precision    Recall  F1 Score  \\\n",
      "0     Logistic Regression  0.846336   0.845911  0.846336  0.844080   \n",
      "1           Decision Tree  0.943262   0.943776  0.943262  0.943307   \n",
      "2           Random Forest  0.955083   0.955594  0.955083  0.955281   \n",
      "3     k-Nearest Neighbors  0.886525   0.885783  0.886525  0.879002   \n",
      "4  Support Vector Machine  0.962175   0.962438  0.962175  0.961988   \n",
      "5          Neural Network  0.770686   0.778511  0.770686  0.766158   \n",
      "\n",
      "                                     Best Parameters  \n",
      "0      {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}  \n",
      "1  {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
      "2  {'max_depth': None, 'min_samples_leaf': 1, 'mi...  \n",
      "3       {'algorithm': 'ball_tree', 'n_neighbors': 3}  \n",
      "4    {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}  \n",
      "5  {'activation': 'relu', 'hidden_layer_sizes': (...  \n"
     ]
    }
   ],
   "source": [
    "# Convert results to DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"Best Parameters\"])\n",
    "print(\"Model Performance Metrics on Test Set after GridSearchCV:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ef36e26-63f7-4650-871e-7d688569babc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation for accuracy on the full dataset using best models\n",
    "cv_results = []\n",
    "for name, classifier in classifiers.items():\n",
    "    # Get the best model from GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=classifier, param_grid=param_grids[name], cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='accuracy')\n",
    "    cv_results.append([name, cv_scores.mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d548eac-a096-4abf-82df-9f6af81affc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Accuracy Scores after GridSearchCV:\n",
      "                    Model  Mean CV Accuracy\n",
      "0     Logistic Regression          0.823861\n",
      "1           Decision Tree          0.922827\n",
      "2           Random Forest          0.936614\n",
      "3     k-Nearest Neighbors          0.883500\n",
      "4  Support Vector Machine          0.938947\n",
      "5          Neural Network          0.761793\n"
     ]
    }
   ],
   "source": [
    "# Display cross-validation results\n",
    "cv_results_df = pd.DataFrame(cv_results, columns=[\"Model\", \"Mean CV Accuracy\"])\n",
    "print(\"\\nCross-Validation Accuracy Scores after GridSearchCV:\")\n",
    "print(cv_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca38f17-8003-4593-ad60-d3572f135077",
   "metadata": {},
   "source": [
    "## References\n",
    "* A case study prepared for HDip in DAB/ AI Applications by Dr. Muhammad Iqbal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
