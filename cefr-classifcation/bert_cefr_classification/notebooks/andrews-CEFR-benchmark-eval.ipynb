{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9609582b-a649-4f70-947d-56e2ad9c3b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3193ee5-de7c-4479-a6ba-2a22c3c1b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "base_dir = os.path.dirname(notebook_dir)\n",
    "experiment_data_folder = os.path.join(base_dir,\"datasets\", \"NLP4CALL_2025_experiment\",\"experiments_data\",\"nlp4call2025_article_experiments\")\n",
    "# efcamdat_100k_with_text_and_measures.csv\n",
    "efcamdat_100k_fp = os.path.join(experiment_data_folder, \"efcamdat_100k_with_text_and_measures.csv\")\n",
    "efcamdat_100k_train_fp = os.path.join(experiment_data_folder, \"efcamdat_train_id.csv\")\n",
    "efcamdat_100k_test_fp = os.path.join(experiment_data_folder, \"efcamdat_test_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a14e4894-6487-4c18-9d2d-07a5d35fe85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class hard_predictions_eval:\n",
    "    def __init__(self, hard_predictions_dict : dict, hard_gold_labels_dict : dict):\n",
    "        self.hard_predictions_dict = hard_predictions_dict\n",
    "        self.hard_gold_labels_dict = hard_gold_labels_dict\n",
    "        self.y_pred = [v for v in self.hard_predictions_dict.values()], \n",
    "        self.y_true = [v for v in self.hard_gold_labels_dict.values()]\n",
    "        print(self.y_pred, self.y_true)\n",
    "    def accuracy(self):\n",
    "        pass\n",
    "    def precision(self):\n",
    "        pass\n",
    "    def recall(self):\n",
    "        pass\n",
    "    def report(self):\n",
    "        # assuming dicts are aligned with all same ids\n",
    "        self.report = classification_report(\n",
    "            [v for v in self.hard_predictions_dict.values()], \n",
    "            [v for v in self.hard_gold_labels_dict.values()]\n",
    "        )\n",
    "        print(self.report)\n",
    "\n",
    "def soft_predictions_eval(predictions, gold_labels):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef512576-cff4-407e-889b-63c0e278e7ee",
   "metadata": {},
   "source": [
    "## Expected folder structure\n",
    "## \n",
    "```\n",
    "./datasets\n",
    "└── NLP4CALL_2025_experiment\n",
    "    ├── experiments_data\n",
    "    │   └── nlp4call2025_article_experiments\n",
    "    │       ├── celva_1742_with_text_and_measures.csv\n",
    "    │       ├── data_for_cefr_model_3efcamdat_to_1celva_with_ids_and_texts.csv\n",
    "    │       ├── efcamdat_100k_with_text_and_measures.csv\n",
    "    │       ├── efcamdat_test_with_id.csv\n",
    "    │       └── efcamdat_train_with_id.csv\n",
    "    └── experiments_data.zip\n",
    "./notebooks\n",
    "└── andrews-CEFR-benchmark-eval.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d2ae16-c5bc-4b73-8b1b-34628bd3c036",
   "metadata": {},
   "source": [
    "## Load dataset and get test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b30616d7-4c00-4ed3-8255-fc54e8c43ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "andrews100kdf = pd.read_csv(efcamdat_100k_fp,index_col=0)\n",
    "andrews100ktrainids = pd.read_csv(efcamdat_100k_train_fp)['writing_id']\n",
    "andrews100ktestids = pd.read_csv(efcamdat_100k_test_fp)['writing_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "40874a82-b6c9-4106-9124-ba0726eb2abb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 725)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "andrews100kdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2bc741d3-71fd-4266-bacf-1588b6b72c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "andrew100ktrain_df = pd.merge(andrews100kdf,andrews100ktrainids,on=\"writing_id\")\n",
    "andrew100ktest_df = pd.merge(andrews100kdf,andrews100ktestids,on=\"writing_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4678f5ef-fa9d-4b75-ad3a-52b550a91a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 725)\n",
      "Index(['writing_id', 'cefr_level',\n",
      "       'measures.collocations.text_level.ratio_num_token',\n",
      "       'measures.collocations.text_level.ttr', 'measures.counts.acl',\n",
      "       'measures.counts.acl_ratio', 'measures.counts.acl:relcl',\n",
      "       'measures.counts.acl:relcl_ratio', 'measures.counts.ADJ',\n",
      "       'measures.counts.ADJ_ratio',\n",
      "       ...\n",
      "       'measures.taassc.L2SCA.CT_T', 'measures.taassc.L2SCA.DC_C',\n",
      "       'measures.taassc.L2SCA.DC_T', 'measures.taassc.L2SCA.MLC',\n",
      "       'measures.taassc.L2SCA.MLS', 'measures.taassc.L2SCA.MLT',\n",
      "       'measures.taassc.L2SCA.T_S', 'measures.taassc.L2SCA.VP_T', 'text',\n",
      "       'l1'],\n",
      "      dtype='object', length=725)\n",
      "(20002, 725)\n",
      "Index(['writing_id', 'cefr_level',\n",
      "       'measures.collocations.text_level.ratio_num_token',\n",
      "       'measures.collocations.text_level.ttr', 'measures.counts.acl',\n",
      "       'measures.counts.acl_ratio', 'measures.counts.acl:relcl',\n",
      "       'measures.counts.acl:relcl_ratio', 'measures.counts.ADJ',\n",
      "       'measures.counts.ADJ_ratio',\n",
      "       ...\n",
      "       'measures.taassc.L2SCA.CT_T', 'measures.taassc.L2SCA.DC_C',\n",
      "       'measures.taassc.L2SCA.DC_T', 'measures.taassc.L2SCA.MLC',\n",
      "       'measures.taassc.L2SCA.MLS', 'measures.taassc.L2SCA.MLT',\n",
      "       'measures.taassc.L2SCA.T_S', 'measures.taassc.L2SCA.VP_T', 'text',\n",
      "       'l1'],\n",
      "      dtype='object', length=725)\n",
      "(79998, 725)\n",
      "Index(['writing_id', 'cefr_level',\n",
      "       'measures.collocations.text_level.ratio_num_token',\n",
      "       'measures.collocations.text_level.ttr', 'measures.counts.acl',\n",
      "       'measures.counts.acl_ratio', 'measures.counts.acl:relcl',\n",
      "       'measures.counts.acl:relcl_ratio', 'measures.counts.ADJ',\n",
      "       'measures.counts.ADJ_ratio',\n",
      "       ...\n",
      "       'measures.taassc.L2SCA.CT_T', 'measures.taassc.L2SCA.DC_C',\n",
      "       'measures.taassc.L2SCA.DC_T', 'measures.taassc.L2SCA.MLC',\n",
      "       'measures.taassc.L2SCA.MLS', 'measures.taassc.L2SCA.MLT',\n",
      "       'measures.taassc.L2SCA.T_S', 'measures.taassc.L2SCA.VP_T', 'text',\n",
      "       'l1'],\n",
      "      dtype='object', length=725)\n"
     ]
    }
   ],
   "source": [
    "for df in [andrews100kdf, andrew100ktest_df, andrew100ktrain_df]:\n",
    "    print(df.shape)\n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2384c8c-2c84-4a16-b728-b5aa638c0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cefr_levels =[\"A1\",\"A2\",\"B1\",\"B2\",\"C1\",\"C2\"]\n",
    "sample_size = 10000\n",
    "dummy_test_set = andrews100kdf.sample(sample_size).reset_index()\n",
    "hard_golden_labels=dummy_test_set[\"cefr_level\"].to_dict()\n",
    "print(hard_golden_labels)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2642a663-1a15-4f20-8df2-e843aba8dc93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hard_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hard_eval \u001b[38;5;241m=\u001b[39m hard_predictions_eval(\u001b[43mhard_predictions\u001b[49m,hard_golden_labels)\n\u001b[1;32m      2\u001b[0m clear_output()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hard_predictions' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f968e-b0af-481a-8379-9630d6b5809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_eval.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856f3f16-248a-4fbe-bd1a-bf4ddd5b130b",
   "metadata": {},
   "source": [
    "### What is the distribution of CEFR level ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32a16b-45c2-4280-ae92-89d2cec08000",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [andrews100kdf, andrew100ktest_df, andrew100ktrain_df]:\n",
    "    print(df[\"cefr_level\"].value_counts()/len(df[\"cefr_level\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd3c24-f07a-41d0-bcc7-f4b3022ebc5f",
   "metadata": {},
   "source": [
    "# Loading a model and doing predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c70dde0-7bc4-48ec-8455-c3f3f56ce292",
   "metadata": {},
   "source": [
    "## Loading flat classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4ccc1-daa3-4c2a-94b4-f98cf92ecaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "model_name=\"CefrFlatMultiClassLogisticRegressionModel\"\n",
    "sys.path.append(base_dir)\n",
    "sys.path.append(f\"{base_dir}{os.sep}modelling\")\n",
    "import flat_classifier as FC\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab867002-7601-48af-8474-a9fe5067ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_dict = FC.load_model(f\"{base_dir}{os.sep}modelling{os.sep}models{os.sep}{model_name}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e70b5d-c4aa-4a95-a358-1c926440bebd",
   "metadata": {},
   "source": [
    "### DUMMY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b79dd-ef03-4043-9088-8af9fe371f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "with torch.no_grad():  # We don't need gradients for inference\n",
    "    random_input = torch.randn(batch_size, model_dict['model_architecture']['input_size'])  #  (3, input_size)\n",
    "    logits, probas= model(random_input)  # Get logits (predictions)\n",
    "    print(\"Model output (logits):\", logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21866275-8e7a-4959-bf08-1cb262b8c10d",
   "metadata": {},
   "source": [
    "### andrew100k_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec9dfd-c6ee-470b-a05f-d57742bb710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "andrew100ktest_df\n",
    "batch_size = andrew100ktest_df.shape[0]\n",
    "with torch.no_grad():  # We don't need gradients for inference\n",
    "    random_input = torch.randn(batch_size, model_dict['model_architecture']['input_size'])  #  (3, input_size)\n",
    "    logits, probas= model(random_input)  # Get logits (predictions)\n",
    "    print(\"Model output (logits):\", logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82d2df-c475-48dc-ab56-e5699febfb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probas = torch.nn.functional.softmax(logits,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58f7a61b-66b1-47a8-b7e4-16221e3bd9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([79998, 6])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac2ec42-3071-445f-b887-211b8d8c574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eab5b0-a645-4d80-a72d-630b7d41b514",
   "metadata": {},
   "source": [
    "## Random Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f047d19-0138-422d-9b7c-410b085f8b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_probas = np.random.dirichlet(np.ones(5),size=sample_size)\n",
    "'''predictions = {\n",
    "    {\n",
    "     \"A1\": 0.31,\n",
    "     \"A2\": 0.54,\n",
    "     \"B1\": 0.4,\n",
    "     \"B2\": 0.74,\n",
    "     \"C1\": 0.74,\n",
    "    }\n",
    "}'''\n",
    "soft_predictions = {\n",
    "    id_: {class_:proba for class_, proba in zip(cefr_levels, cefr_vector)}\n",
    "    for id_, cefr_vector in zip(range(sample_size),random_probas.tolist())\n",
    "}\n",
    "idx_to_class_ = lambda v: {\n",
    "         0: \"A1\",\n",
    "         1: \"A2\",\n",
    "         2: \"B1\",\n",
    "         3: \"B2\",\n",
    "         4: \"C1\",\n",
    "}.get(v, None)\n",
    "hard_predictions = {k:idx_to_class_(v) for k,v in zip(range(sample_size), np.argmax(random_probas,axis=1).tolist())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d293ae92-68bd-455d-b146-bacedd3ce2c1",
   "metadata": {},
   "source": [
    "## Evaluating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64517bf3-900c-4b79-8dfd-605b4e244de6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hard_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hard_eval \u001b[38;5;241m=\u001b[39m hard_predictions_eval(\u001b[43mhard_predictions\u001b[49m,hard_golden_labels)\n\u001b[1;32m      2\u001b[0m clear_output()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hard_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "hard_eval = hard_predictions_eval(hard_predictions,hard_golden_labels)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44553aea-59dd-40fb-83bc-a88c8f3791de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
