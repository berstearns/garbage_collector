{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d66ae503-7b7c-4cae-a3dc-051a0cd37118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0155ff6-46a1-4ee4-aa82-4592f8e4d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "base_dir = os.path.dirname(notebook_dir)\n",
    "celva_data_folder = os.path.join(base_dir,\"datasets\", \"CELVA\")\n",
    "celva_dataset_fp = os.path.join(celva_data_folder, \"features_celva.csv\")\n",
    "idx_to_class_ = lambda v: {\n",
    "         0: \"A1\",\n",
    "         1: \"A2\",\n",
    "         2: \"B1\",\n",
    "         3: \"B2\",\n",
    "         4: \"C1\",\n",
    "         5: \"C1\",\n",
    "}.get(v, None)\n",
    "label_to_idx_ = lambda v: {\n",
    "         \"A1\": 0,\n",
    "         \"A2\": 1,\n",
    "         \"B1\": 2,\n",
    "         \"B2\": 3,\n",
    "         \"C1\": 4,\n",
    "         \"C2\": 4,\n",
    "}.get(v, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee08541-99e8-427f-b14a-9e9985d1ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "base_dir = os.path.dirname(notebook_dir)\n",
    "experiment_data_folder = os.path.join(base_dir,\"datasets\", \"NLP4CALL_2025_experiment\",\"experiments_data\")\n",
    "# efcamdat_100k_with_text_and_measures.csv\n",
    "efcamdat_100k_fp = os.path.join(experiment_data_folder, \"efcamdat_100k_with_text_and_measures.csv\")\n",
    "efcamdat_100k_train_fp = os.path.join(experiment_data_folder, \"efcamdat_train_id.csv\")\n",
    "efcamdat_100k_test_fp = os.path.join(experiment_data_folder, \"efcamdat_test_id.csv\")\n",
    "efcamdat_100k_train_fe_fp = os.path.join(experiment_data_folder, \"andrew100ktrain_df_fe.csv\")\n",
    "efcamdat_100k_test_fe_fp = os.path.join(experiment_data_folder, \"andrew100ktest_df_fe.csv\")\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"text_column\": \"text\",\n",
    "    \"column_mapping\": {\n",
    "        \"remainder_efcamdat\": {\n",
    "            \"text\":\"\",\n",
    "            \"CEFR\":\"?\"\n",
    "        },\n",
    "        \"andrew100k\": {\n",
    "            \"text\": \"text\",\n",
    "            \"CEFR\":\"cefr_level\"\n",
    "        }\n",
    "    },\n",
    "    \"train_output_fp\": os.path.join(experiment_data_folder, \"andrew100k-train-fe.csv\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e78750-896f-4ef5-b3dd-dc56f953a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(efcamdat_100k_train_fe_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5db696d3-ef81-435d-83b5-8335a6b9b1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writing_id</th>\n",
       "      <th>cefr_level</th>\n",
       "      <th>measures.collocations.text_level.ratio_num_token</th>\n",
       "      <th>measures.collocations.text_level.ttr</th>\n",
       "      <th>measures.counts.acl</th>\n",
       "      <th>measures.counts.acl_ratio</th>\n",
       "      <th>measures.counts.acl:relcl</th>\n",
       "      <th>measures.counts.acl:relcl_ratio</th>\n",
       "      <th>measures.counts.ADJ</th>\n",
       "      <th>measures.counts.ADJ_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>measures.taassc.L2SCA.T_S</th>\n",
       "      <th>measures.taassc.L2SCA.VP_T</th>\n",
       "      <th>text</th>\n",
       "      <th>l1</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>tokens_per_sentence</th>\n",
       "      <th>total_n_tokens</th>\n",
       "      <th>avg_n_tokens_per_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115499</td>\n",
       "      <td>b1</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>3</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>grandmas home remedies and recipes. Do you hav...</td>\n",
       "      <td>German</td>\n",
       "      <td>grandmas home remedies and recipes. Do you hav...</td>\n",
       "      <td>['grandmas home remedies and recipes.', 'Do yo...</td>\n",
       "      <td>8</td>\n",
       "      <td>[['grandmas', 'home', 'remedies', 'and', 'reci...</td>\n",
       "      <td>92</td>\n",
       "      <td>11.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1081381</td>\n",
       "      <td>a1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>My friend is very nice.She comes from Italy.Sh...</td>\n",
       "      <td>Italian</td>\n",
       "      <td>My friend is very nice.She comes from Italy.Sh...</td>\n",
       "      <td>['My friend is very nice.She comes from Italy....</td>\n",
       "      <td>2</td>\n",
       "      <td>[['My', 'friend', 'is', 'very', 'nice.She', 'c...</td>\n",
       "      <td>32</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>452770</td>\n",
       "      <td>b1</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>First, I will study a lot and finish my degree...</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>First, I will study a lot and finish my degree...</td>\n",
       "      <td>['First, I will study a lot and finish my degr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[['First', ',', 'I', 'will', 'study', 'a', 'lo...</td>\n",
       "      <td>125</td>\n",
       "      <td>125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>412035</td>\n",
       "      <td>a1</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Hy, my name's Andr. I have thirty one years ol...</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>Hy, my name's Andr. I have thirty one years ol...</td>\n",
       "      <td>[\"Hy, my name's Andr.\", 'I have thirty one yea...</td>\n",
       "      <td>6</td>\n",
       "      <td>[['Hy', ',', 'my', 'name', \"'s\", 'Andr', '.'],...</td>\n",
       "      <td>40</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132380</td>\n",
       "      <td>b1</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>6</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>bello! I glad to congratulate you with the bes...</td>\n",
       "      <td>Russian</td>\n",
       "      <td>bello! I glad to congratulate you with the bes...</td>\n",
       "      <td>['bello!', 'I glad to congratulate you with th...</td>\n",
       "      <td>11</td>\n",
       "      <td>[['bello', '!'], ['I', 'glad', 'to', 'congratu...</td>\n",
       "      <td>95</td>\n",
       "      <td>8.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79993</th>\n",
       "      <td>1136689</td>\n",
       "      <td>b1</td>\n",
       "      <td>0.135922</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.077670</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>Dear Ali, I hope this letter finds you in a go...</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Dear Ali, I hope this letter finds you in a go...</td>\n",
       "      <td>['Dear Ali, I hope this letter finds you in a ...</td>\n",
       "      <td>8</td>\n",
       "      <td>[['Dear', 'Ali', ',', 'I', 'hope', 'this', 'le...</td>\n",
       "      <td>103</td>\n",
       "      <td>12.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79994</th>\n",
       "      <td>797042</td>\n",
       "      <td>a1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>3</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>My piano and Me I am not re ally into my piano...</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>My piano and Me I am not re ally into my piano...</td>\n",
       "      <td>['My piano and Me I am not re ally into my pia...</td>\n",
       "      <td>3</td>\n",
       "      <td>[['My', 'piano', 'and', 'Me', 'I', 'am', 'not'...</td>\n",
       "      <td>36</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>628121</td>\n",
       "      <td>a2</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>4</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Dear Louis, I''m very happy with the new that ...</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>Dear Louis, I''m very happy with the new that ...</td>\n",
       "      <td>[\"Dear Louis, I''m very happy with the new tha...</td>\n",
       "      <td>3</td>\n",
       "      <td>[['Dear', 'Louis', ',', 'I', \"''\", 'm', 'very'...</td>\n",
       "      <td>86</td>\n",
       "      <td>28.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>211344</td>\n",
       "      <td>a2</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>9</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>...</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.181818</td>\n",
       "      <td>Yes , today I have a bad day,have a bad taste ...</td>\n",
       "      <td>Mandarin</td>\n",
       "      <td>Yes , today I have a bad day,have a bad taste ...</td>\n",
       "      <td>['Yes , today I have a bad day,have a bad tast...</td>\n",
       "      <td>5</td>\n",
       "      <td>[['Yes', ',', 'today', 'I', 'have', 'a', 'bad'...</td>\n",
       "      <td>91</td>\n",
       "      <td>18.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>859984</td>\n",
       "      <td>a1</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>...</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>I'm really into my guitar. I'ts very old but i...</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>I'm really into my guitar. I'ts very old but i...</td>\n",
       "      <td>[\"I'm really into my guitar.\", \"I'ts very old ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[['I', \"'m\", 'really', 'into', 'my', 'guitar',...</td>\n",
       "      <td>51</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79998 rows × 731 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       writing_id cefr_level  \\\n",
       "0          115499         b1   \n",
       "1         1081381         a1   \n",
       "2          452770         b1   \n",
       "3          412035         a1   \n",
       "4          132380         b1   \n",
       "...           ...        ...   \n",
       "79993     1136689         b1   \n",
       "79994      797042         a1   \n",
       "79995      628121         a2   \n",
       "79996      211344         a2   \n",
       "79997      859984         a1   \n",
       "\n",
       "       measures.collocations.text_level.ratio_num_token  \\\n",
       "0                                              0.108696   \n",
       "1                                              0.111111   \n",
       "2                                              0.176000   \n",
       "3                                              0.050000   \n",
       "4                                              0.061224   \n",
       "...                                                 ...   \n",
       "79993                                          0.135922   \n",
       "79994                                          0.000000   \n",
       "79995                                          0.074074   \n",
       "79996                                          0.064516   \n",
       "79997                                          0.037736   \n",
       "\n",
       "       measures.collocations.text_level.ttr  measures.counts.acl  \\\n",
       "0                                  1.000000                    2   \n",
       "1                                  1.000000                    0   \n",
       "2                                  1.000000                    2   \n",
       "3                                  1.000000                    0   \n",
       "4                                  1.000000                    0   \n",
       "...                                     ...                  ...   \n",
       "79993                              0.857143                    0   \n",
       "79994                              0.000000                    0   \n",
       "79995                              1.000000                    2   \n",
       "79996                              1.000000                    0   \n",
       "79997                              1.000000                    0   \n",
       "\n",
       "       measures.counts.acl_ratio  measures.counts.acl:relcl  \\\n",
       "0                       0.021739                          1   \n",
       "1                       0.000000                          0   \n",
       "2                       0.016000                          1   \n",
       "3                       0.000000                          0   \n",
       "4                       0.000000                          1   \n",
       "...                          ...                        ...   \n",
       "79993                   0.000000                          0   \n",
       "79994                   0.000000                          1   \n",
       "79995                   0.024691                          1   \n",
       "79996                   0.000000                          1   \n",
       "79997                   0.000000                          0   \n",
       "\n",
       "       measures.counts.acl:relcl_ratio  measures.counts.ADJ  \\\n",
       "0                             0.010870                    3   \n",
       "1                             0.000000                    6   \n",
       "2                             0.008000                    5   \n",
       "3                             0.000000                    2   \n",
       "4                             0.010204                    6   \n",
       "...                                ...                  ...   \n",
       "79993                         0.000000                    8   \n",
       "79994                         0.027027                    3   \n",
       "79995                         0.012346                    4   \n",
       "79996                         0.010753                    9   \n",
       "79997                         0.000000                    4   \n",
       "\n",
       "       measures.counts.ADJ_ratio  ...  measures.taassc.L2SCA.T_S  \\\n",
       "0                       0.032609  ...                   1.000000   \n",
       "1                       0.166667  ...                   3.000000   \n",
       "2                       0.040000  ...                   9.000000   \n",
       "3                       0.050000  ...                   0.666667   \n",
       "4                       0.061224  ...                   0.818182   \n",
       "...                          ...  ...                        ...   \n",
       "79993                   0.077670  ...                   1.500000   \n",
       "79994                   0.081081  ...                   0.666667   \n",
       "79995                   0.049383  ...                   1.333333   \n",
       "79996                   0.096774  ...                   2.200000   \n",
       "79997                   0.075472  ...                   1.600000   \n",
       "\n",
       "       measures.taassc.L2SCA.VP_T  \\\n",
       "0                        1.500000   \n",
       "1                        1.000000   \n",
       "2                        1.777778   \n",
       "3                        1.500000   \n",
       "4                        1.777778   \n",
       "...                           ...   \n",
       "79993                    1.416667   \n",
       "79994                    1.000000   \n",
       "79995                    1.500000   \n",
       "79996                    1.181818   \n",
       "79997                    1.000000   \n",
       "\n",
       "                                                    text          l1  \\\n",
       "0      grandmas home remedies and recipes. Do you hav...      German   \n",
       "1      My friend is very nice.She comes from Italy.Sh...     Italian   \n",
       "2      First, I will study a lot and finish my degree...  Portuguese   \n",
       "3      Hy, my name's Andr. I have thirty one years ol...  Portuguese   \n",
       "4      bello! I glad to congratulate you with the bes...     Russian   \n",
       "...                                                  ...         ...   \n",
       "79993  Dear Ali, I hope this letter finds you in a go...      Arabic   \n",
       "79994  My piano and Me I am not re ally into my piano...      Arabic   \n",
       "79995  Dear Louis, I''m very happy with the new that ...  Portuguese   \n",
       "79996  Yes , today I have a bad day,have a bad taste ...    Mandarin   \n",
       "79997  I'm really into my guitar. I'ts very old but i...  Portuguese   \n",
       "\n",
       "                                            cleaned_text  \\\n",
       "0      grandmas home remedies and recipes. Do you hav...   \n",
       "1      My friend is very nice.She comes from Italy.Sh...   \n",
       "2      First, I will study a lot and finish my degree...   \n",
       "3      Hy, my name's Andr. I have thirty one years ol...   \n",
       "4      bello! I glad to congratulate you with the bes...   \n",
       "...                                                  ...   \n",
       "79993  Dear Ali, I hope this letter finds you in a go...   \n",
       "79994  My piano and Me I am not re ally into my piano...   \n",
       "79995  Dear Louis, I''m very happy with the new that ...   \n",
       "79996  Yes , today I have a bad day,have a bad taste ...   \n",
       "79997  I'm really into my guitar. I'ts very old but i...   \n",
       "\n",
       "                                               sentences  n_sentences  \\\n",
       "0      ['grandmas home remedies and recipes.', 'Do yo...            8   \n",
       "1      ['My friend is very nice.She comes from Italy....            2   \n",
       "2      ['First, I will study a lot and finish my degr...            1   \n",
       "3      [\"Hy, my name's Andr.\", 'I have thirty one yea...            6   \n",
       "4      ['bello!', 'I glad to congratulate you with th...           11   \n",
       "...                                                  ...          ...   \n",
       "79993  ['Dear Ali, I hope this letter finds you in a ...            8   \n",
       "79994  ['My piano and Me I am not re ally into my pia...            3   \n",
       "79995  [\"Dear Louis, I''m very happy with the new tha...            3   \n",
       "79996  ['Yes , today I have a bad day,have a bad tast...            5   \n",
       "79997  [\"I'm really into my guitar.\", \"I'ts very old ...            5   \n",
       "\n",
       "                                     tokens_per_sentence  total_n_tokens  \\\n",
       "0      [['grandmas', 'home', 'remedies', 'and', 'reci...              92   \n",
       "1      [['My', 'friend', 'is', 'very', 'nice.She', 'c...              32   \n",
       "2      [['First', ',', 'I', 'will', 'study', 'a', 'lo...             125   \n",
       "3      [['Hy', ',', 'my', 'name', \"'s\", 'Andr', '.'],...              40   \n",
       "4      [['bello', '!'], ['I', 'glad', 'to', 'congratu...              95   \n",
       "...                                                  ...             ...   \n",
       "79993  [['Dear', 'Ali', ',', 'I', 'hope', 'this', 'le...             103   \n",
       "79994  [['My', 'piano', 'and', 'Me', 'I', 'am', 'not'...              36   \n",
       "79995  [['Dear', 'Louis', ',', 'I', \"''\", 'm', 'very'...              86   \n",
       "79996  [['Yes', ',', 'today', 'I', 'have', 'a', 'bad'...              91   \n",
       "79997  [['I', \"'m\", 'really', 'into', 'my', 'guitar',...              51   \n",
       "\n",
       "       avg_n_tokens_per_sentence  \n",
       "0                      11.500000  \n",
       "1                      16.000000  \n",
       "2                     125.000000  \n",
       "3                       6.666667  \n",
       "4                       8.636364  \n",
       "...                          ...  \n",
       "79993                  12.875000  \n",
       "79994                  12.000000  \n",
       "79995                  28.666667  \n",
       "79996                  18.200000  \n",
       "79997                  10.200000  \n",
       "\n",
       "[79998 rows x 731 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3116bcef-a84b-43ad-afb8-89a9b498ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create different classifiers.\n",
    "classifiers = {\n",
    "    \"L2 logistic (Multinomial)\": LogisticRegression(\n",
    "        C=1, penalty=\"l2\", solver=\"saga\", max_iter=10000\n",
    "    ),\n",
    "    #\"L2 logistic (OvR)\": OneVsRestClassifier(\n",
    "    #    LogisticRegression(C=C, penalty=\"l2\", solver=\"saga\", max_iter=10000)\n",
    "    #)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bc96c9ff-f95d-44c4-8f36-16b2a9324368",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    \"n_sentences\": [\"n_sentences\"],\n",
    "    \"n-sent+n-tokens\": [\"n_sentences\",\"total_n_tokens\"],\n",
    "    \"avg-sent+n-sent+n-tokens\": [\"n_sentences\",\"total_n_tokens\",\"avg_n_tokens_per_sentence\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "14663156-a652-4d7d-b7b6-48f0e816a3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pseudo', 'Voc_range', 'CECRL', 'nb_annees_L2', 'L1',\n",
       "       'Domaine_de_specialite', 'Sejours_duree_semaines', 'Sejours_frequence',\n",
       "       'Lang_exposition', 'L2', 'Note_dialang_ecrit', 'Lecture_regularite',\n",
       "       'autre_langue', 'tache_ecrit', 'Texte_etudiant', 'Date_ajout',\n",
       "       'Section_renforcee', 'CEFR', 'cleaned_text', 'sentences', 'n_sentences',\n",
       "       'tokens_per_sentence', 'total_n_tokens', 'avg_n_tokens_per_sentence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "62774182-2ec0-4d2c-ab3d-97198b848f50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36015325670498083\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36590038314176243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35946462715105165\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40344168260038243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3544061302681992\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4091778202676864\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36015325670498083\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3173996175908222\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3524904214559387\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3632887189292543\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3524904214559387\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3524904214559387\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3946360153256705\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3544061302681992\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4099616858237548\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40535372848948376\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3403441682600382\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34674329501915707\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3977055449330784\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3946360153256705\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35564053537284895\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3403441682600382\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.390057361376673\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3505747126436782\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3938814531548757\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34674329501915707\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35372848948374763\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3486590038314176\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.390057361376673\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36590038314176243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32567049808429116\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3632887189292543\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39080459770114945\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3632887189292543\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.41762452107279696\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4340344168260038\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35946462715105165\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.32950191570881227\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32375478927203066\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3938814531548757\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3544061302681992\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.33460803059273425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4072657743785851\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39579349904397704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.40535372848948376\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4072657743785851\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.40152963671128106\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3632887189292543\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40535372848948376\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35823754789272033\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37093690248565964\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35823754789272033\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4099616858237548\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3371647509578544\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40344168260038243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.36015325670498083\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35372848948374763\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.31800766283524906\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.34099616858237547\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.31800766283524906\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3326959847036329\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.4118773946360153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.390057361376673\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3448275862068966\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4130019120458891\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3946360153256705\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.32695984703632885\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3544061302681992\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34608030592734224\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34099616858237547\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37093690248565964\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39579349904397704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.342911877394636\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.41379310344827586\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3448275862068966\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3422562141491396\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4187380497131931\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3575525812619503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39846743295019155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4272030651340996\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39579349904397704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.342911877394636\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4168260038240918\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34608030592734224\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.42528735632183906\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3938814531548757\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37093690248565964\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36015325670498083\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39961759082217974\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3938814531548757\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3486590038314176\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32375478927203066\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4130019120458891\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35564053537284895\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3479923518164436\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.4061302681992337\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4118773946360153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35181644359464626\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32695984703632885\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.34608030592734224\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32887189292543023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3938814531548757\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.28107074569789675\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3524904214559387\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3479923518164436\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3575525812619503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3575525812619503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3422562141491396\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4099616858237548\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4149139579349904\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.342911877394636\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39846743295019155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36590038314176243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3275862068965517\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39961759082217974\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3365200764818356\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35372848948374763\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.34674329501915707\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3078393881453155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39961759082217974\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.40152963671128106\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3275862068965517\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39579349904397704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36590038314176243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.2988505747126437\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.34099616858237547\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35372848948374763\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39961759082217974\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35823754789272033\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3505747126436782\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3977055449330784\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3632887189292543\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39846743295019155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3326959847036329\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3135755258126195\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.4118773946360153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4061302681992337\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35564053537284895\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40535372848948376\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35946462715105165\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.2988505747126437\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3314176245210728\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.33078393881453155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36590038314176243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3135755258126195\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3575525812619503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4168260038240918\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3326959847036329\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4149139579349904\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.40152963671128106\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32122370936902483\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3314176245210728\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3632887189292543\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3486590038314176\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39961759082217974\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3333333333333333\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35181644359464626\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40152963671128106\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3479923518164436\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35181644359464626\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.31417624521072796\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3371647509578544\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3938814531548757\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.33078393881453155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.41762452107279696\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3938814531548757\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35181644359464626\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32695984703632885\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3632887189292543\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.33078393881453155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39579349904397704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.40152963671128106\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36015325670498083\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40152963671128106\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3946360153256705\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3524904214559387\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3448275862068966\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37093690248565964\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35946462715105165\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.33524904214559387\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37093690248565964\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37093690248565964\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4386973180076628\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3977055449330784\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3505747126436782\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39579349904397704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40344168260038243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3575525812619503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3314176245210728\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.390057361376673\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.41379310344827586\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35372848948374763\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34099616858237547\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3575525812619503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4072657743785851\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3479923518164436\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.4099616858237548\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32567049808429116\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39846743295019155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.4061302681992337\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3154875717017208\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36590038314176243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.35564053537284895\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3422562141491396\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39080459770114945\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4272030651340996\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.33460803059273425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32504780114722753\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.35564053537284895\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3505747126436782\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.42829827915869984\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3422562141491396\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39579349904397704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3403441682600382\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.31417624521072796\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.33524904214559387\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4225621414913958\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.390057361376673\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3448275862068966\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3977055449330784\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.30975143403441685\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3275862068965517\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3977055449330784\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35946462715105165\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35946462715105165\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3575525812619503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.42911877394636017\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3365200764818356\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39846743295019155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3946360153256705\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3365200764818356\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4061302681992337\n"
     ]
    }
   ],
   "source": [
    "target_column = \"CEFR\"\n",
    "cv_results = defaultdict(lambda: defaultdict(dict))\n",
    "for epoch_idx in range(100):\n",
    "    dataset = df.sample(frac=1)\n",
    "    pipes = product(classifiers.values(), features.values())\n",
    "    for model, feature_list in pipes:\n",
    "        columns = feature_list+[target_column]\n",
    "        kf = KFold(n_splits=2)\n",
    "        model_idx = str(model)+str(feature_list)\n",
    "        for cv_idx,(train_idx, test_idx) in enumerate(kf.split(dataset)):\n",
    "            X_train = dataset.iloc[train_idx][feature_list]\n",
    "            X_test  = dataset.iloc[test_idx][feature_list]\n",
    "            y_train = dataset.iloc[train_idx][target_column]\n",
    "            y_test  = dataset.iloc[test_idx][target_column]\n",
    "            model.fit(X_train, y_train)\n",
    "            target_names = ['A1', 'A2', 'B1', 'B2', 'C1']\n",
    "            y_pred = model.predict(X_test)\n",
    "            results_dict = classification_report(y_test, y_pred, target_names=target_names,output_dict=True)\n",
    "            cv_results[model_idx][\"accuracies\"][str(epoch_idx)+str(cv_idx)] = results_dict[\"accuracy\"]\n",
    "            cv_results[model_idx][\"results\"][str(epoch_idx)+str(cv_idx)] = results_dict\n",
    "            print(model_idx, results_dict[\"accuracy\"])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "951b14a0-ca0c-4d3e-b080-12116e32d670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        L1\n",
       "2   French\n",
       "4   French\n",
       "10  French"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[2,4,10]][[\"L1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0050ea3c-b303-411e-86be-d78e596f35ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37244137491483703\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3618688417104386\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38900617568844637\n"
     ]
    }
   ],
   "source": [
    "for strat, data in cv_results.items():\n",
    "    print(strat, sum(data[\"accuracies\"].values())/len(data[\"accuracies\"].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e02fee6-366a-4462-bb74-e73ee55282f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8ac776-3ce9-4b60-9989-63390d7d6094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98bcdb6-77ad-4c0a-88e1-caa26cfadf28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
