{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d66ae503-7b7c-4cae-a3dc-051a0cd37118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f0155ff6-46a1-4ee4-aa82-4592f8e4d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "base_dir = os.path.dirname(notebook_dir)\n",
    "celva_data_folder = os.path.join(base_dir,\"datasets\", \"CELVA\")\n",
    "celva_dataset_fp = os.path.join(celva_data_folder, \"features_celva.csv\")\n",
    "idx_to_class_ = lambda v: {\n",
    "         0: \"A1\",\n",
    "         1: \"A2\",\n",
    "         2: \"B1\",\n",
    "         3: \"B2\",\n",
    "         4: \"C1\",\n",
    "         5: \"C1\",\n",
    "}.get(v, None)\n",
    "label_to_idx_ = lambda v: {\n",
    "         \"A1\": 0,\n",
    "         \"A2\": 1,\n",
    "         \"B1\": 2,\n",
    "         \"B2\": 3,\n",
    "         \"C1\": 4,\n",
    "         \"C2\": 4,\n",
    "}.get(v, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "96e78750-896f-4ef5-b3dd-dc56f953a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(celva_dataset_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5db696d3-ef81-435d-83b5-8335a6b9b1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudo</th>\n",
       "      <th>Voc_range</th>\n",
       "      <th>CECRL</th>\n",
       "      <th>nb_annees_L2</th>\n",
       "      <th>L1</th>\n",
       "      <th>Domaine_de_specialite</th>\n",
       "      <th>Sejours_duree_semaines</th>\n",
       "      <th>Sejours_frequence</th>\n",
       "      <th>Lang_exposition</th>\n",
       "      <th>L2</th>\n",
       "      <th>...</th>\n",
       "      <th>Texte_etudiant</th>\n",
       "      <th>Date_ajout</th>\n",
       "      <th>Section_renforcee</th>\n",
       "      <th>CEFR</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>tokens_per_sentence</th>\n",
       "      <th>total_n_tokens</th>\n",
       "      <th>avg_n_tokens_per_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>030928d2a04fd0035312d8a75a2403acfe29ac41f07cdf...</td>\n",
       "      <td>B1</td>\n",
       "      <td>B1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>French</td>\n",
       "      <td>Sciences et proprietes de la matiere</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Anglais</td>\n",
       "      <td>...</td>\n",
       "      <td>being in a earth sciences domain at the beginn...</td>\n",
       "      <td>2019-03-22 11:14:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>being in a earth sciences domain at the beginn...</td>\n",
       "      <td>['being in a earth sciences domain at the begi...</td>\n",
       "      <td>15</td>\n",
       "      <td>[['being', 'in', 'a', 'earth', 'sciences', 'do...</td>\n",
       "      <td>350</td>\n",
       "      <td>23.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09eec567ab0b705caf2353e10849bcf3579749d8e9ac84...</td>\n",
       "      <td>A2</td>\n",
       "      <td>A2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>French</td>\n",
       "      <td>Information Communication</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Anglais</td>\n",
       "      <td>...</td>\n",
       "      <td>alex dupont had an important role during ww2. ...</td>\n",
       "      <td>2022-09-14 14:51:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>alex dupont had an important role during ww2. ...</td>\n",
       "      <td>['alex dupont had an important role during ww2...</td>\n",
       "      <td>15</td>\n",
       "      <td>[['alex', 'dupont', 'had', 'an', 'important', ...</td>\n",
       "      <td>279</td>\n",
       "      <td>18.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1296d11065e5441e2a97223619841ee5a204979254c0a6...</td>\n",
       "      <td>B1</td>\n",
       "      <td>B1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>French</td>\n",
       "      <td>Medecine</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Anglais</td>\n",
       "      <td>...</td>\n",
       "      <td>in the 20th century alex dupont discovered pen...</td>\n",
       "      <td>2018-10-24 10:21:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>in the 20th century alex dupont discovered pen...</td>\n",
       "      <td>['in the 20th century alex dupont discovered p...</td>\n",
       "      <td>20</td>\n",
       "      <td>[['in', 'the', '20th', 'century', 'alex', 'dup...</td>\n",
       "      <td>249</td>\n",
       "      <td>12.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f2dd72bc867a07a8a11579ddd2345b3d9851622289c5c...</td>\n",
       "      <td>B2</td>\n",
       "      <td>C1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>French</td>\n",
       "      <td>Information Communication</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Anglais</td>\n",
       "      <td>...</td>\n",
       "      <td>b b at the beginning phones were only used to ...</td>\n",
       "      <td>2022-02-21 15:19:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>b b at the beginning phones were only used to ...</td>\n",
       "      <td>['b b at the beginning phones were only used t...</td>\n",
       "      <td>27</td>\n",
       "      <td>[['b', 'b', 'at', 'the', 'beginning', 'phones'...</td>\n",
       "      <td>510</td>\n",
       "      <td>18.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2ad05299cb18cb201810933a85f3157d8e885a4490156f...</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>French</td>\n",
       "      <td>Medecine</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Anglais</td>\n",
       "      <td>...</td>\n",
       "      <td>as we know a lot of lives are saved everyday t...</td>\n",
       "      <td>2020-03-03 12:25:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>as we know a lot of lives are saved everyday t...</td>\n",
       "      <td>['as we know a lot of lives are saved everyday...</td>\n",
       "      <td>11</td>\n",
       "      <td>[['as', 'we', 'know', 'a', 'lot', 'of', 'lives...</td>\n",
       "      <td>226</td>\n",
       "      <td>20.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>6103f5729ab058a7d71cee4245a776e3b3333be57b41fd...</td>\n",
       "      <td>C1</td>\n",
       "      <td>C1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>French</td>\n",
       "      <td>Informatique et electronique</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Anglais</td>\n",
       "      <td>...</td>\n",
       "      <td>since my childhood i have been educated with s...</td>\n",
       "      <td>2022-09-14 11:44:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>since my childhood i have been educated with s...</td>\n",
       "      <td>['since my childhood i have been educated with...</td>\n",
       "      <td>13</td>\n",
       "      <td>[['since', 'my', 'childhood', 'i', 'have', 'be...</td>\n",
       "      <td>342</td>\n",
       "      <td>26.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>da55b42254c2c4764937c4af1544cd1f0520d75b47076a...</td>\n",
       "      <td>A1</td>\n",
       "      <td>A1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>French</td>\n",
       "      <td>Sciences de la vie et de l'environnement</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Anglais</td>\n",
       "      <td>...</td>\n",
       "      <td>experience of fibroblastes scientifics discove...</td>\n",
       "      <td>2018-11-22 10:51:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>experience of fibroblastes scientifics discove...</td>\n",
       "      <td>['experience of fibroblastes scientifics disco...</td>\n",
       "      <td>4</td>\n",
       "      <td>[['experience', 'of', 'fibroblastes', 'scienti...</td>\n",
       "      <td>53</td>\n",
       "      <td>13.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>f468edb2f584f2bfc530953308d80e2b7c7b1e001a2e37...</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>French</td>\n",
       "      <td>Information Communication</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Anglais</td>\n",
       "      <td>...</td>\n",
       "      <td>first of all i would like to talk about the in...</td>\n",
       "      <td>2021-01-29 10:28:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>first of all i would like to talk about the in...</td>\n",
       "      <td>['first of all i would like to talk about the ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[['first', 'of', 'all', 'i', 'would', 'like', ...</td>\n",
       "      <td>241</td>\n",
       "      <td>24.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>86aedd1988a47388c8edbfbd3a5fa26de2644f7beed390...</td>\n",
       "      <td>B1</td>\n",
       "      <td>B1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>French</td>\n",
       "      <td>Sciences de l'education</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Anglais</td>\n",
       "      <td>...</td>\n",
       "      <td>hello my name is alex dupont im 20 years old. ...</td>\n",
       "      <td>2022-09-12 14:53:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>hello my name is alex dupont im 20 years old. ...</td>\n",
       "      <td>['hello my name is alex dupont im 20 years old...</td>\n",
       "      <td>14</td>\n",
       "      <td>[['hello', 'my', 'name', 'is', 'alex', 'dupont...</td>\n",
       "      <td>232</td>\n",
       "      <td>16.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>cafd2d8ed43cbe0f4c4ba4f733785c3eeb5db2426626bc...</td>\n",
       "      <td>B1</td>\n",
       "      <td>B1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>French</td>\n",
       "      <td>Information Communication</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Anglais</td>\n",
       "      <td>...</td>\n",
       "      <td>in the following text i am going to explain wh...</td>\n",
       "      <td>2022-09-14 14:37:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>in the following text i am going to explain wh...</td>\n",
       "      <td>['in the following text i am going to explain ...</td>\n",
       "      <td>19</td>\n",
       "      <td>[['in', 'the', 'following', 'text', 'i', 'am',...</td>\n",
       "      <td>329</td>\n",
       "      <td>17.315789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1045 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 pseudo Voc_range CECRL  \\\n",
       "0     030928d2a04fd0035312d8a75a2403acfe29ac41f07cdf...        B1    B1   \n",
       "1     09eec567ab0b705caf2353e10849bcf3579749d8e9ac84...        A2    A2   \n",
       "2     1296d11065e5441e2a97223619841ee5a204979254c0a6...        B1    B1   \n",
       "3     1f2dd72bc867a07a8a11579ddd2345b3d9851622289c5c...        B2    C1   \n",
       "4     2ad05299cb18cb201810933a85f3157d8e885a4490156f...        B2    B2   \n",
       "...                                                 ...       ...   ...   \n",
       "1040  6103f5729ab058a7d71cee4245a776e3b3333be57b41fd...        C1    C1   \n",
       "1041  da55b42254c2c4764937c4af1544cd1f0520d75b47076a...        A1    A1   \n",
       "1042  f468edb2f584f2bfc530953308d80e2b7c7b1e001a2e37...        B2    B2   \n",
       "1043  86aedd1988a47388c8edbfbd3a5fa26de2644f7beed390...        B1    B1   \n",
       "1044  cafd2d8ed43cbe0f4c4ba4f733785c3eeb5db2426626bc...        B1    B1   \n",
       "\n",
       "      nb_annees_L2      L1                     Domaine_de_specialite  \\\n",
       "0             11.0  French      Sciences et proprietes de la matiere   \n",
       "1              7.0  French                 Information Communication   \n",
       "2             10.0  French                                  Medecine   \n",
       "3             12.0  French                 Information Communication   \n",
       "4              9.0  French                                  Medecine   \n",
       "...            ...     ...                                       ...   \n",
       "1040          13.0  French              Informatique et electronique   \n",
       "1041           8.0  French  Sciences de la vie et de l'environnement   \n",
       "1042           8.0  French                 Information Communication   \n",
       "1043           9.0  French                   Sciences de l'education   \n",
       "1044           7.0  French                 Information Communication   \n",
       "\n",
       "      Sejours_duree_semaines  Sejours_frequence  Lang_exposition       L2  \\\n",
       "0                        6.0                  5              0.0  Anglais   \n",
       "1                        1.0                  1              3.0  Anglais   \n",
       "2                        2.0                  1              2.0  Anglais   \n",
       "3                        0.0                  0             10.0  Anglais   \n",
       "4                        0.0                  0              2.0  Anglais   \n",
       "...                      ...                ...              ...      ...   \n",
       "1040                     2.5                  4             70.0  Anglais   \n",
       "1041                     2.0                  1              1.0  Anglais   \n",
       "1042                     0.0                  0              0.0  Anglais   \n",
       "1043                     0.0                  0              0.0  Anglais   \n",
       "1044                     1.0                  2              1.0  Anglais   \n",
       "\n",
       "      ...                                     Texte_etudiant  \\\n",
       "0     ...  being in a earth sciences domain at the beginn...   \n",
       "1     ...  alex dupont had an important role during ww2. ...   \n",
       "2     ...  in the 20th century alex dupont discovered pen...   \n",
       "3     ...  b b at the beginning phones were only used to ...   \n",
       "4     ...  as we know a lot of lives are saved everyday t...   \n",
       "...   ...                                                ...   \n",
       "1040  ...  since my childhood i have been educated with s...   \n",
       "1041  ...  experience of fibroblastes scientifics discove...   \n",
       "1042  ...  first of all i would like to talk about the in...   \n",
       "1043  ...  hello my name is alex dupont im 20 years old. ...   \n",
       "1044  ...  in the following text i am going to explain wh...   \n",
       "\n",
       "               Date_ajout Section_renforcee CEFR  \\\n",
       "0     2019-03-22 11:14:00                 0    2   \n",
       "1     2022-09-14 14:51:00                 0    1   \n",
       "2     2018-10-24 10:21:00                 1    2   \n",
       "3     2022-02-21 15:19:00                 1    4   \n",
       "4     2020-03-03 12:25:00                 0    3   \n",
       "...                   ...               ...  ...   \n",
       "1040  2022-09-14 11:44:00                 0    4   \n",
       "1041  2018-11-22 10:51:00                 0    0   \n",
       "1042  2021-01-29 10:28:00                 0    3   \n",
       "1043  2022-09-12 14:53:00                 0    2   \n",
       "1044  2022-09-14 14:37:00                 1    2   \n",
       "\n",
       "                                           cleaned_text  \\\n",
       "0     being in a earth sciences domain at the beginn...   \n",
       "1     alex dupont had an important role during ww2. ...   \n",
       "2     in the 20th century alex dupont discovered pen...   \n",
       "3     b b at the beginning phones were only used to ...   \n",
       "4     as we know a lot of lives are saved everyday t...   \n",
       "...                                                 ...   \n",
       "1040  since my childhood i have been educated with s...   \n",
       "1041  experience of fibroblastes scientifics discove...   \n",
       "1042  first of all i would like to talk about the in...   \n",
       "1043  hello my name is alex dupont im 20 years old. ...   \n",
       "1044  in the following text i am going to explain wh...   \n",
       "\n",
       "                                              sentences  n_sentences  \\\n",
       "0     ['being in a earth sciences domain at the begi...           15   \n",
       "1     ['alex dupont had an important role during ww2...           15   \n",
       "2     ['in the 20th century alex dupont discovered p...           20   \n",
       "3     ['b b at the beginning phones were only used t...           27   \n",
       "4     ['as we know a lot of lives are saved everyday...           11   \n",
       "...                                                 ...          ...   \n",
       "1040  ['since my childhood i have been educated with...           13   \n",
       "1041  ['experience of fibroblastes scientifics disco...            4   \n",
       "1042  ['first of all i would like to talk about the ...           10   \n",
       "1043  ['hello my name is alex dupont im 20 years old...           14   \n",
       "1044  ['in the following text i am going to explain ...           19   \n",
       "\n",
       "                                    tokens_per_sentence total_n_tokens  \\\n",
       "0     [['being', 'in', 'a', 'earth', 'sciences', 'do...            350   \n",
       "1     [['alex', 'dupont', 'had', 'an', 'important', ...            279   \n",
       "2     [['in', 'the', '20th', 'century', 'alex', 'dup...            249   \n",
       "3     [['b', 'b', 'at', 'the', 'beginning', 'phones'...            510   \n",
       "4     [['as', 'we', 'know', 'a', 'lot', 'of', 'lives...            226   \n",
       "...                                                 ...            ...   \n",
       "1040  [['since', 'my', 'childhood', 'i', 'have', 'be...            342   \n",
       "1041  [['experience', 'of', 'fibroblastes', 'scienti...             53   \n",
       "1042  [['first', 'of', 'all', 'i', 'would', 'like', ...            241   \n",
       "1043  [['hello', 'my', 'name', 'is', 'alex', 'dupont...            232   \n",
       "1044  [['in', 'the', 'following', 'text', 'i', 'am',...            329   \n",
       "\n",
       "     avg_n_tokens_per_sentence  \n",
       "0                    23.333333  \n",
       "1                    18.600000  \n",
       "2                    12.450000  \n",
       "3                    18.888889  \n",
       "4                    20.545455  \n",
       "...                        ...  \n",
       "1040                 26.307692  \n",
       "1041                 13.250000  \n",
       "1042                 24.100000  \n",
       "1043                 16.571429  \n",
       "1044                 17.315789  \n",
       "\n",
       "[1045 rows x 24 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3116bcef-a84b-43ad-afb8-89a9b498ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create different classifiers.\n",
    "classifiers = {\n",
    "    \"L2 logistic (Multinomial)\": LogisticRegression(\n",
    "        C=1, penalty=\"l2\", solver=\"saga\", max_iter=10000\n",
    "    ),\n",
    "    #\"L2 logistic (OvR)\": OneVsRestClassifier(\n",
    "    #    LogisticRegression(C=C, penalty=\"l2\", solver=\"saga\", max_iter=10000)\n",
    "    #)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bc96c9ff-f95d-44c4-8f36-16b2a9324368",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    \"n_sentences\": [\"n_sentences\"],\n",
    "    \"n-sent+n-tokens\": [\"n_sentences\",\"total_n_tokens\"],\n",
    "    \"avg-sent+n-sent+n-tokens\": [\"n_sentences\",\"total_n_tokens\",\"avg_n_tokens_per_sentence\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "14663156-a652-4d7d-b7b6-48f0e816a3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pseudo', 'Voc_range', 'CECRL', 'nb_annees_L2', 'L1',\n",
       "       'Domaine_de_specialite', 'Sejours_duree_semaines', 'Sejours_frequence',\n",
       "       'Lang_exposition', 'L2', 'Note_dialang_ecrit', 'Lecture_regularite',\n",
       "       'autre_langue', 'tache_ecrit', 'Texte_etudiant', 'Date_ajout',\n",
       "       'Section_renforcee', 'CEFR', 'cleaned_text', 'sentences', 'n_sentences',\n",
       "       'tokens_per_sentence', 'total_n_tokens', 'avg_n_tokens_per_sentence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "62774182-2ec0-4d2c-ab3d-97198b848f50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36015325670498083\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36590038314176243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35946462715105165\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40344168260038243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3544061302681992\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4091778202676864\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36015325670498083\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3173996175908222\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3524904214559387\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3632887189292543\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3524904214559387\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3524904214559387\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3946360153256705\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3544061302681992\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4099616858237548\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40535372848948376\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3403441682600382\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34674329501915707\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3977055449330784\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3946360153256705\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35564053537284895\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3403441682600382\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.390057361376673\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3505747126436782\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3938814531548757\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34674329501915707\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35372848948374763\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3486590038314176\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.390057361376673\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36590038314176243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32567049808429116\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3632887189292543\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39080459770114945\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3632887189292543\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.41762452107279696\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4340344168260038\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35946462715105165\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.32950191570881227\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32375478927203066\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3938814531548757\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3544061302681992\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.33460803059273425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4072657743785851\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39579349904397704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.40535372848948376\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4072657743785851\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.40152963671128106\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3632887189292543\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40535372848948376\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35823754789272033\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37093690248565964\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35823754789272033\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4099616858237548\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3371647509578544\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40344168260038243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.36015325670498083\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35372848948374763\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.31800766283524906\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.34099616858237547\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.31800766283524906\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3326959847036329\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.4118773946360153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.390057361376673\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3448275862068966\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4130019120458891\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3946360153256705\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.32695984703632885\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3544061302681992\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34608030592734224\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34099616858237547\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37093690248565964\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39579349904397704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.342911877394636\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.41379310344827586\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3448275862068966\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3422562141491396\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4187380497131931\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3575525812619503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39846743295019155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4272030651340996\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39579349904397704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.342911877394636\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4168260038240918\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34608030592734224\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.42528735632183906\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3938814531548757\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37093690248565964\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36015325670498083\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39961759082217974\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3938814531548757\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3486590038314176\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32375478927203066\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4130019120458891\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35564053537284895\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3479923518164436\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.4061302681992337\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4118773946360153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35181644359464626\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32695984703632885\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.34608030592734224\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32887189292543023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3938814531548757\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.28107074569789675\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3524904214559387\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3479923518164436\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3575525812619503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3575525812619503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3422562141491396\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4099616858237548\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4149139579349904\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.342911877394636\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39846743295019155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36590038314176243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3275862068965517\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39961759082217974\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3365200764818356\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35372848948374763\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.34674329501915707\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3078393881453155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39961759082217974\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.40152963671128106\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3275862068965517\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39579349904397704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36590038314176243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.2988505747126437\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.34099616858237547\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35372848948374763\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39961759082217974\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35823754789272033\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3505747126436782\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3977055449330784\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3632887189292543\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39846743295019155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3326959847036329\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3135755258126195\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.4118773946360153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4061302681992337\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35564053537284895\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40535372848948376\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35946462715105165\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.2988505747126437\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3314176245210728\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.33078393881453155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36590038314176243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3135755258126195\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3575525812619503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4168260038240918\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3326959847036329\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4149139579349904\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.40152963671128106\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32122370936902483\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3314176245210728\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3632887189292543\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3486590038314176\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39961759082217974\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3333333333333333\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35181644359464626\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40152963671128106\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3479923518164436\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35181644359464626\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.31417624521072796\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3371647509578544\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3938814531548757\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.33078393881453155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.41762452107279696\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3938814531548757\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35181644359464626\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32695984703632885\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3632887189292543\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.33078393881453155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39579349904397704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.40152963671128106\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36015325670498083\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40152963671128106\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3946360153256705\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3524904214559387\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3448275862068966\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37093690248565964\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35946462715105165\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.33524904214559387\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37093690248565964\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37093690248565964\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.4042145593869732\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4386973180076628\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.361376673040153\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3977055449330784\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3505747126436782\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39579349904397704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40344168260038243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3575525812619503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3314176245210728\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.390057361376673\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.41379310344827586\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35372848948374763\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.34099616858237547\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3575525812619503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.4003831417624521\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4072657743785851\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37547892720306514\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3479923518164436\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.4099616858237548\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40804597701149425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3831417624521073\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32567049808429116\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39846743295019155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.4061302681992337\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3154875717017208\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36590038314176243\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.35564053537284895\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367112810707457\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3850574712643678\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3422562141491396\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39080459770114945\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37476099426386233\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4272030651340996\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.33460803059273425\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.32504780114722753\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.35564053537284895\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.372848948374761\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3505747126436782\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.42829827915869984\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.34990439770554493\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3422562141491396\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3563218390804598\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39579349904397704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3881453154875717\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38697318007662834\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3403441682600382\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.31417624521072796\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37858508604206503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.33524904214559387\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4225621414913958\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3793103448275862\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.36398467432950193\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.390057361376673\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3448275862068966\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3977055449330784\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3888888888888889\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.367816091954023\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.30975143403441685\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3620689655172414\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.36973180076628354\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3652007648183556\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3384321223709369\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3919694072657744\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3773946360153257\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38049713193116635\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.38122605363984674\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.37667304015296366\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3275862068965517\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3977055449330784\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.39655172413793105\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.35946462715105165\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.35946462715105165\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.40229885057471265\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3575525812619503\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.42911877394636017\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3735632183908046\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3365200764818356\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39846743295019155\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3690248565965583\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3946360153256705\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3862332695984704\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.3716475095785441\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3365200764818356\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.39272030651340994\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.3824091778202677\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.4061302681992337\n"
     ]
    }
   ],
   "source": [
    "target_column = \"CEFR\"\n",
    "cv_results = defaultdict(lambda: defaultdict(dict))\n",
    "for epoch_idx in range(100):\n",
    "    dataset = df.sample(frac=1)\n",
    "    pipes = product(classifiers.values(), features.values())\n",
    "    for model, feature_list in pipes:\n",
    "        columns = feature_list+[target_column]\n",
    "        kf = KFold(n_splits=2)\n",
    "        model_idx = str(model)+str(feature_list)\n",
    "        for cv_idx,(train_idx, test_idx) in enumerate(kf.split(dataset)):\n",
    "            X_train = dataset.iloc[train_idx][feature_list]\n",
    "            X_test  = dataset.iloc[test_idx][feature_list]\n",
    "            y_train = dataset.iloc[train_idx][target_column]\n",
    "            y_test  = dataset.iloc[test_idx][target_column]\n",
    "            model.fit(X_train, y_train)\n",
    "            target_names = ['A1', 'A2', 'B1', 'B2', 'C1']\n",
    "            y_pred = model.predict(X_test)\n",
    "            results_dict = classification_report(y_test, y_pred, target_names=target_names,output_dict=True)\n",
    "            cv_results[model_idx][\"accuracies\"][str(epoch_idx)+str(cv_idx)] = results_dict[\"accuracy\"]\n",
    "            cv_results[model_idx][\"results\"][str(epoch_idx)+str(cv_idx)] = results_dict\n",
    "            print(model_idx, results_dict[\"accuracy\"])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "951b14a0-ca0c-4d3e-b080-12116e32d670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        L1\n",
       "2   French\n",
       "4   French\n",
       "10  French"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[2,4,10]][[\"L1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0050ea3c-b303-411e-86be-d78e596f35ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences'] 0.37244137491483703\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens'] 0.3618688417104386\n",
      "LogisticRegression(C=1, max_iter=10000, solver='saga')['n_sentences', 'total_n_tokens', 'avg_n_tokens_per_sentence'] 0.38900617568844637\n"
     ]
    }
   ],
   "source": [
    "for strat, data in cv_results.items():\n",
    "    print(strat, sum(data[\"accuracies\"].values())/len(data[\"accuracies\"].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e02fee6-366a-4462-bb74-e73ee55282f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8ac776-3ce9-4b60-9989-63390d7d6094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98bcdb6-77ad-4c0a-88e1-caa26cfadf28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
